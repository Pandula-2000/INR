{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-09-22T09:53:28.141813Z",
     "start_time": "2024-09-22T09:53:24.492723Z"
    }
   },
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import os\n",
    "from skimage.util import random_noise\n",
    "from PIL import Image\n",
    "from torchvision.transforms import Resize, Compose, ToTensor, Normalize\n",
    "import numpy as np\n",
    "import skimage\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "from Models.SIREN import Siren",
   "id": "ea3ee961721d741",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def get_mgrid(sidelen, dim=2):\n",
    "    '''Generates a flattened grid of (x,y,...) coordinates in a range of -1 to 1.\n",
    "    sidelen: int\n",
    "    dim: int'''\n",
    "    tensors = tuple(dim * [torch.linspace(-1, 1, steps=sidelen)])\n",
    "    mgrid = torch.stack(torch.meshgrid(*tensors), dim=-1)\n",
    "    mgrid = mgrid.reshape(-1, dim)\n",
    "    return mgrid"
   ],
   "id": "306a9d05c588aed0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "sidelen = 3\n",
    "dim = 2\n",
    "tensors = tuple(dim * [torch.linspace(-1, 1, steps=sidelen)])\n",
    "torch.meshgrid(*tensors)"
   ],
   "id": "1a9e99fdd9ff07f8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Differential Operators",
   "id": "efb8d3c0792eefdd"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def laplace(y, x):\n",
    "    grad = gradient(y, x)\n",
    "    return divergence(grad, x)\n",
    "\n",
    "\n",
    "def divergence(y, x):\n",
    "    div = 0.\n",
    "    for i in range(y.shape[-1]):\n",
    "        div += torch.autograd.grad(y[..., i], x, torch.ones_like(y[..., i]), create_graph=True)[0][..., i:i+1]\n",
    "    return div\n",
    "\n",
    "\n",
    "def gradient(y, x, grad_outputs=None):\n",
    "    if grad_outputs is None:\n",
    "        grad_outputs = torch.ones_like(y)\n",
    "    grad = torch.autograd.grad(y, [x], grad_outputs=grad_outputs, create_graph=True)[0]\n",
    "    return grad"
   ],
   "id": "8ac42796b2f76841",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Get Image",
   "id": "5e978822147ae8d9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def get_cameraman_tensor(sidelength):\n",
    "    img = Image.fromarray(skimage.data.camera())        \n",
    "    transform = Compose([\n",
    "        Resize(sidelength),\n",
    "        ToTensor(),\n",
    "        Normalize(torch.Tensor([0.5]), torch.Tensor([0.5]))\n",
    "    ])\n",
    "    img = transform(img)\n",
    "    return img"
   ],
   "id": "938eb53b56a95805",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "print(get_cameraman_tensor(256).shape)",
   "id": "db2efcf8379a7247",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Fit the Image",
   "id": "db03cae980480fbf"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "class ImageFitting(Dataset):\n",
    "    def __init__(self, sidelength, noisy=False, mode = None, var = None, amount=None):\n",
    "        super().__init__()\n",
    "        img = get_cameraman_tensor(sidelength)\n",
    "        if noisy:\n",
    "            if mode=='gaussian':\n",
    "                img = torch.from_numpy(random_noise(img, mode=mode, var= var))\n",
    "            elif mode=='s&p':\n",
    "                img = torch.from_numpy(random_noise(img, mode=mode, amount=amount))\n",
    "            else:\n",
    "                img = torch.from_numpy(random_noise(img, mode='localvar'))\n",
    "                \n",
    "        self.pixels = img.permute(1, 2, 0).view(-1, 1)\n",
    "        self.coords = get_mgrid(sidelength, 2)\n",
    "\n",
    "    def __len__(self):\n",
    "        return 1\n",
    "\n",
    "    def __getitem__(self, idx):    \n",
    "        if idx > 0: raise IndexError\n",
    "    \n",
    "        return self.coords, self.pixels"
   ],
   "id": "b4e8e21c5d2725b6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Ground Truths for Different Noises",
   "id": "d5c364ae9ef72314"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Assuming you have the ImageFitting instance 'cameraman'\n",
    "cameraman = ImageFitting(256, noisy=False)\n",
    "\n",
    "# Get the image tensor and reshape it to 2D\n",
    "image_tensor = cameraman.pixels.view(256, 256)\n",
    "\n",
    "# Convert the tensor to numpy array for visualization\n",
    "image_array = image_tensor.numpy()\n",
    "noisy_image_r = random_noise(image_array, mode='localvar')\n",
    "noisy_image_g = random_noise(image_array, mode='gaussian', var= 0.2)\n",
    "noisy_image_p = random_noise(image_array, mode='s&p', amount=0.5)\n",
    "# Use matplotlib to visualize the image\n",
    "\n",
    "fig, axes = plt.subplots(1,4, figsize=(18,6))\n",
    "axes[0].imshow(image_array, cmap='gray')\n",
    "axes[0].set_title(\"Original Image\")\n",
    "axes[1].imshow(noisy_image_r, cmap='gray')\n",
    "axes[1].set_title(\"Noisy Image (random noise)\")\n",
    "axes[2].imshow(noisy_image_g, cmap='gray')\n",
    "axes[2].set_title(\"Noisy Image (gaussian noise)\")\n",
    "axes[3].imshow(noisy_image_p, cmap='gray')\n",
    "axes[3].set_title(\"Noisy Image (s and p)\")\n",
    "# plt.imshow(image_array.cpu().view(256,256).detach().numpy())\n",
    "plt.show()\n"
   ],
   "id": "a77dea8d02f1f66d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## GRADIENT AND LAPLACIAN COMPUTATION",
   "id": "4b56e08bd62f6e80"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import scipy.ndimage\n",
    "\n",
    "def compute_gradient(image):\n",
    "    # Compute gradients along x and y directions\n",
    "    dx = scipy.ndimage.sobel(image, axis=0, mode='constant')\n",
    "    dy = scipy.ndimage.sobel(image, axis=1, mode='constant')\n",
    "    return dx, dy\n",
    "\n",
    "def compute_laplacian(image):\n",
    "    # Compute the Laplacian using a convolution with a specific kernel\n",
    "    laplacian_kernel = np.array([[0, 1, 0],\n",
    "                                 [1, -4, 1],\n",
    "                                 [0, 1, 0]])\n",
    "    laplacian = scipy.ndimage.convolve(image, laplacian_kernel, mode='constant')\n",
    "    return laplacian\n",
    "\n"
   ],
   "id": "b06ca79a9f213811",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "cameraman = ImageFitting(256, noisy=True, mode='localvar')\n",
    "#cameraman = ImageFitting(256, noisy=True, mode='s&p',amount =0.1)\n",
    "#cameraman = ImageFitting(256)\n",
    "\n",
    "# Get the image tensor and reshape it to 2D\n",
    "image_tensor = cameraman.pixels.view(256, 256)\n",
    "\n",
    "# Convert the tensor to numpy array for visualization\n",
    "image_array = image_tensor.numpy()\n",
    "\n",
    "# Assuming 'image_tensor' is your image tensor and already converted to a numpy array\n",
    "# For example, if your tensor is a PyTorch tensor, you can convert it to numpy array using image_tensor.numpy()\n",
    "\n",
    "# Compute gradient\n",
    "dx, dy = compute_gradient(image_array)\n",
    "\n",
    "# Compute Laplacian\n",
    "laplacian = compute_laplacian(image_array)\n",
    "\n",
    "fig, axes = plt.subplots(1,4, figsize=(18,6))\n",
    "axes[0].imshow(image_array, cmap='gray')\n",
    "axes[0].set_title(\"Original Image\")\n",
    "axes[1].imshow(dx, cmap='gray')\n",
    "axes[1].set_title(\"Gradient along x\")\n",
    "axes[2].imshow(dy, cmap='gray')\n",
    "axes[2].set_title(\"Gradient along y\")\n",
    "axes[3].imshow(laplacian, cmap='gray')\n",
    "axes[3].set_title(\"Laplacian\")"
   ],
   "id": "1548e087adc9df18",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Load the dataset",
   "id": "5ddf7726c32ace65"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#cameraman = ImageFitting(256)\n",
    "#cameraman = ImageFitting(256, noisy=True, mode='gaussian', var=0.2)\n",
    "#cameraman = ImageFitting(256, noisy=True, mode='s&p',amount =0.1)\n",
    "cameraman = ImageFitting(256, noisy=True, mode='localvar')\n",
    "\n",
    "dataloader = DataLoader(cameraman, batch_size=1, pin_memory=True, num_workers=0)\n",
    "\n",
    "img_siren = Siren(in_features=2, out_features=1, hidden_features=256, \n",
    "                  hidden_layers=3, outermost_linear=True)\n",
    "img_siren.cuda()"
   ],
   "id": "1487ddc1e4a9dd3d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "img = get_cameraman_tensor(256)\n",
    "img_n = torch.from_numpy(random_noise(img))\n",
    "print(img_n.shape)"
   ],
   "id": "3c3da2ed04a12ffe",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# TRAINING LOOP",
   "id": "9df661403c8549bd"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "total_steps = 300 # Since the whole image is our dataset, this just means 500 gradient descent steps.\n",
    "steps_til_summary = 10\n",
    "\n",
    "optim = torch.optim.Adam(lr=1e-4, params=img_siren.parameters())\n",
    "\n",
    "model_input, ground_truth = next(iter(dataloader))\n",
    "model_input, ground_truth = model_input.cuda(), ground_truth.cuda()\n",
    "\n",
    "loss_array = []\n",
    "\n",
    "for step in range(total_steps):\n",
    "    model_output, coords = img_siren(model_input)    \n",
    "    loss = ((model_output - ground_truth)**2).mean()\n",
    "    loss_array.append(loss.detach().cpu().numpy())\n",
    "    \n",
    "    if not step % steps_til_summary:\n",
    "        print(\"Step %d, Total loss %0.6f\" % (step, loss))\n",
    "        img_grad_x, image_grad_y = compute_gradient(model_output.cpu().view(256 ,256).detach().numpy())\n",
    "        img_laplacian = compute_laplacian(model_output.cpu().view(256 ,256).detach().numpy())\n",
    "\n",
    "        fig, axes = plt.subplots(1 ,4, figsize=(18 ,6))\n",
    "        axes[0].imshow(model_output.cpu().view(256 ,256).detach().numpy(), cmap='gray')\n",
    "        axes[0].set_title(\"Trained Image\")\n",
    "        axes[1].imshow(img_grad_x, cmap='gray')\n",
    "        axes[1].set_title(\"Gradient along x\")\n",
    "        axes[2].imshow(image_grad_y, cmap='gray')\n",
    "        axes[2].set_title(\"Gradient along y\")\n",
    "        axes[3].imshow(img_laplacian, cmap='gray')\n",
    "        axes[3].set_title(\"Laplacian\")\n",
    "        plt.show()\n",
    "\n",
    "    optim.zero_grad()\n",
    "    loss.backward()\n",
    "    optim.step()\n"
   ],
   "id": "c78e230d2cc31809",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "print(loss.detach().cpu().numpy())",
   "id": "a66c287a67dded26",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Plot the loss curve",
   "id": "ab19ed4142c4eac9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "plt.plot(loss_array)\n",
    "plt.xlabel('iteration')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ],
   "id": "4893f9d9974e069b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "with torch.no_grad():\n",
    "    coords = get_mgrid(2**10, 1) * 5 * np.pi\n",
    "    \n",
    "    sin_1 = torch.sin(coords)\n",
    "    sin_2 = torch.sin(coords * 2)\n",
    "    sum = sin_1 + sin_2\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(16,2))\n",
    "    ax.plot(coords, sum)\n",
    "    ax.plot(coords, sin_1)\n",
    "    ax.plot(coords, sin_2)\n",
    "    plt.title(\"Rational multiple\")\n",
    "    plt.show()\n",
    "    \n",
    "    sin_1 = torch.sin(coords)\n",
    "    sin_2 = torch.sin(coords * np.pi)\n",
    "    sum = sin_1 + sin_2\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(16,2))\n",
    "    ax.plot(coords, sum)\n",
    "    ax.plot(coords, sin_1)\n",
    "    ax.plot(coords, sin_2)\n",
    "    plt.title(\"Pseudo-irrational multiple\")\n",
    "    plt.show()"
   ],
   "id": "950cd432d4b124b3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "with torch.no_grad():\n",
    "    out_of_range_coords = get_mgrid(1024, 2) * 50\n",
    "    model_out, _ = img_siren(out_of_range_coords.cuda())\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(16,16))\n",
    "    ax.imshow(model_out.cpu().view(1024,1024).numpy())\n",
    "    plt.show()"
   ],
   "id": "24831fb01c753f61",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
