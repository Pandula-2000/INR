{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import os\n",
    "from skimage.util import random_noise\n",
    "from PIL import Image\n",
    "from torchvision.transforms import Resize, Compose, ToTensor, Normalize\n",
    "import numpy as np\n",
    "import skimage\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import time"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def get_mgrid(sidelen, dim=2):\n",
    "    '''Generates a flattened grid of (x,y,...) coordinates in a range of -1 to 1.\n",
    "    sidelen: int\n",
    "    dim: int'''\n",
    "    tensors = tuple(dim * [torch.linspace(-1, 1, steps=sidelen)])\n",
    "    mgrid = torch.stack(torch.meshgrid(*tensors), dim=-1)\n",
    "    mgrid = mgrid.reshape(-1, dim)\n",
    "    return mgrid"
   ],
   "id": "306a9d05c588aed0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "get_mgrid(3)",
   "id": "ea3ee961721d741",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "sidelen = 3\n",
    "dim = 2\n",
    "tensors = tuple(dim * [torch.linspace(-1, 1, steps=sidelen)])\n",
    "torch.meshgrid(*tensors)"
   ],
   "id": "1a9e99fdd9ff07f8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "class SineLayer(nn.Module):\n",
    "    # See paper sec. 3.2, final paragraph, and supplement Sec. 1.5 for discussion of omega_0.\n",
    "    \n",
    "    # If is_first=True, omega_0 is a frequency factor which simply multiplies the activations before the \n",
    "    # nonlinearity. Different signals may require different omega_0 in the first layer - this is a \n",
    "    # hyperparameter.\n",
    "    \n",
    "    # If is_first=False, then the weights will be divided by omega_0 so as to keep the magnitude of \n",
    "    # activations constant, but boost gradients to the weight matrix (see supplement Sec. 1.5)\n",
    "    \n",
    "    def __init__(self, in_features, out_features, bias=True,\n",
    "                 is_first=False, omega_0=30):\n",
    "        super().__init__()\n",
    "        self.omega_0 = omega_0\n",
    "        self.is_first = is_first\n",
    "        \n",
    "        self.in_features = in_features\n",
    "        self.linear = nn.Linear(in_features, out_features, bias=bias)\n",
    "        \n",
    "        self.init_weights()\n",
    "    \n",
    "    def init_weights(self):\n",
    "        with torch.no_grad():\n",
    "            if self.is_first:\n",
    "                self.linear.weight.uniform_(-1 / self.in_features, \n",
    "                                             1 / self.in_features)      \n",
    "            else:\n",
    "                self.linear.weight.uniform_(-np.sqrt(6 / self.in_features) / self.omega_0, \n",
    "                                             np.sqrt(6 / self.in_features) / self.omega_0)\n",
    "        \n",
    "    def forward(self, input):\n",
    "        return torch.sin(self.omega_0 * self.linear(input))\n",
    "    \n",
    "    def forward_with_intermediate(self, input): \n",
    "        # For visualization of activation distributions\n",
    "        intermediate = self.omega_0 * self.linear(input)\n",
    "        return torch.sin(intermediate), intermediate"
   ],
   "id": "8a81b86c68a32a52",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "class Siren(nn.Module):\n",
    "    def __init__(self, in_features, hidden_features, hidden_layers, out_features, outermost_linear=False, \n",
    "                 first_omega_0=30, hidden_omega_0=30.):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.net = []\n",
    "        self.net.append(SineLayer(in_features, hidden_features, \n",
    "                                  is_first=True, omega_0=first_omega_0))\n",
    "\n",
    "        for i in range(hidden_layers):\n",
    "            self.net.append(SineLayer(hidden_features, hidden_features, \n",
    "                                      is_first=False, omega_0=hidden_omega_0))\n",
    "\n",
    "        if outermost_linear:\n",
    "            final_linear = nn.Linear(hidden_features, out_features)\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                final_linear.weight.uniform_(-np.sqrt(6 / hidden_features) / hidden_omega_0, \n",
    "                                              np.sqrt(6 / hidden_features) / hidden_omega_0)\n",
    "                \n",
    "            self.net.append(final_linear)\n",
    "        else:\n",
    "            self.net.append(SineLayer(hidden_features, out_features, \n",
    "                                      is_first=False, omega_0=hidden_omega_0))\n",
    "        \n",
    "        self.net = nn.Sequential(*self.net)\n",
    "    \n",
    "    def forward(self, coords):\n",
    "        coords = coords.clone().detach().requires_grad_(True) # allows to take derivative w.r.t. input\n",
    "        output = self.net(coords)\n",
    "        return output, coords        \n",
    "\n",
    "    def forward_with_activations(self, coords, retain_grad=False):\n",
    "        '''Returns not only model output, but also intermediate activations.\n",
    "        Only used for visualizing activations later!'''\n",
    "        activations = OrderedDict()\n",
    "\n",
    "        activation_count = 0\n",
    "        x = coords.clone().detach().requires_grad_(True)\n",
    "        activations['input'] = x\n",
    "        for i, layer in enumerate(self.net):\n",
    "            if isinstance(layer, SineLayer):\n",
    "                x, intermed = layer.forward_with_intermediate(x)\n",
    "                \n",
    "                if retain_grad:\n",
    "                    x.retain_grad()\n",
    "                    intermed.retain_grad()\n",
    "                    \n",
    "                activations['_'.join((str(layer.__class__), \"%d\" % activation_count))] = intermed\n",
    "                activation_count += 1\n",
    "            else: \n",
    "                x = layer(x)\n",
    "                \n",
    "                if retain_grad:\n",
    "                    x.retain_grad()\n",
    "                    \n",
    "            activations['_'.join((str(layer.__class__), \"%d\" % activation_count))] = x\n",
    "            activation_count += 1\n",
    "\n",
    "        return activations"
   ],
   "id": "df584c151b752778",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**Differential Operators**",
   "id": "efb8d3c0792eefdd"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def laplace(y, x):\n",
    "    grad = gradient(y, x)\n",
    "    return divergence(grad, x)\n",
    "\n",
    "\n",
    "def divergence(y, x):\n",
    "    div = 0.\n",
    "    for i in range(y.shape[-1]):\n",
    "        div += torch.autograd.grad(y[..., i], x, torch.ones_like(y[..., i]), create_graph=True)[0][..., i:i+1]\n",
    "    return div\n",
    "\n",
    "\n",
    "def gradient(y, x, grad_outputs=None):\n",
    "    if grad_outputs is None:\n",
    "        grad_outputs = torch.ones_like(y)\n",
    "    grad = torch.autograd.grad(y, [x], grad_outputs=grad_outputs, create_graph=True)[0]\n",
    "    return grad"
   ],
   "id": "8ac42796b2f76841",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**Get Image**",
   "id": "5e978822147ae8d9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def get_cameraman_tensor(sidelength):\n",
    "    img = Image.fromarray(skimage.data.camera())        \n",
    "    transform = Compose([\n",
    "        Resize(sidelength),\n",
    "        ToTensor(),\n",
    "        Normalize(torch.Tensor([0.5]), torch.Tensor([0.5]))\n",
    "    ])\n",
    "    img = transform(img)\n",
    "    return img"
   ],
   "id": "938eb53b56a95805",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "print(get_cameraman_tensor(256).shape)",
   "id": "db2efcf8379a7247",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**Fit the Image**",
   "id": "db03cae980480fbf"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "class ImageFitting(Dataset):\n",
    "    def __init__(self, sidelength):\n",
    "        super().__init__()\n",
    "        img = get_cameraman_tensor(sidelength)\n",
    "        noisy_image = torch.from_numpy(random_noise(img, mode='gaussian', var= 0.2))\n",
    "        self.pixels = noisy_image.permute(1, 2, 0).view(-1, 1)\n",
    "        self.coords = get_mgrid(sidelength, 2)\n",
    "\n",
    "    def __len__(self):\n",
    "        return 1\n",
    "\n",
    "    def __getitem__(self, idx):    \n",
    "        if idx > 0: raise IndexError\n",
    "    \n",
    "        return self.coords, self.pixels"
   ],
   "id": "b4e8e21c5d2725b6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "cameraman = ImageFitting(256)\n",
    "dataloader = DataLoader(cameraman, batch_size=1, pin_memory=True, num_workers=0)\n",
    "\n",
    "img_siren = Siren(in_features=2, out_features=1, hidden_features=256, \n",
    "                  hidden_layers=3, outermost_linear=True)\n",
    "img_siren.cuda()"
   ],
   "id": "1487ddc1e4a9dd3d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "img = get_cameraman_tensor(256)\n",
    "img_n = torch.from_numpy(random_noise(img))\n",
    "print(img_n.shape)"
   ],
   "id": "3c3da2ed04a12ffe",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Assuming you have the ImageFitting instance 'cameraman'\n",
    "cameraman = ImageFitting(256)\n",
    "\n",
    "# Get the image tensor and reshape it to 2D\n",
    "image_tensor = cameraman.pixels.view(256, 256)\n",
    "\n",
    "# Convert the tensor to numpy array for visualization\n",
    "image_array = image_tensor.numpy()\n",
    "noisy_image_r = random_noise(image_array, mode='localvar')\n",
    "noisy_image_g = random_noise(image_array, mode='gaussian', var= 0.2)\n",
    "noisy_image_p = random_noise(image_array, mode='s&p', amount=0.5)\n",
    "# Use matplotlib to visualize the image\n",
    "\n",
    "fig, axes = plt.subplots(1,4, figsize=(18,6))\n",
    "axes[0].imshow(image_array, cmap='gray')\n",
    "axes[0].set_title(\"Original Image\")\n",
    "axes[1].imshow(noisy_image_r, cmap='gray')\n",
    "axes[1].set_title(\"Noisy Image (random noise)\")\n",
    "axes[2].imshow(noisy_image_g, cmap='gray')\n",
    "axes[2].set_title(\"Noisy Image (gaussian noise)\")\n",
    "axes[3].imshow(noisy_image_p, cmap='gray')\n",
    "axes[3].set_title(\"Noisy Image (s and p)\")\n",
    "# plt.imshow(image_array.cpu().view(256,256).detach().numpy())\n",
    "plt.show()\n"
   ],
   "id": "a77dea8d02f1f66d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# # Assuming you have the ImageFitting instance 'cameraman'\n",
    "# cameraman = ImageFitting(256)\n",
    "# \n",
    "# # Get the image tensor and reshape it to 2D\n",
    "# img = cameraman.pixels.view(256, 256)\n",
    "# img_grad = gradient(img, coords)\n",
    "# img_laplacian = laplace(img, coords)\n",
    "# # Convert the tensor to numpy array for visualization\n",
    "# img = image_tensor.numpy()\n",
    "# \n",
    "# \n",
    "# fig, axes = plt.subplots(1,4, figsize=(18,6))\n",
    "# axes[0].imshow(img, cmap='gray')\n",
    "# axes[0].set_title(\"Original Image\")\n",
    "# # axes[1].imshow(noisy_image_, cmap='gray')\n",
    "# # axes[1].set_title(\"Noisy Image (random noise)\")\n",
    "# # axes[2].imshow(noisy_image_g, cmap='gray')\n",
    "# # axes[2].set_title(\"Noisy Image (gaussian noise)\")\n",
    "# \n",
    "# \n",
    "# plt.show()"
   ],
   "id": "c16b059b377c7bbd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "total_steps = 500 # Since the whole image is our dataset, this just means 500 gradient descent steps.\n",
    "steps_til_summary = 10\n",
    "\n",
    "optim = torch.optim.Adam(lr=1e-4, params=img_siren.parameters())\n",
    "\n",
    "model_input, ground_truth = next(iter(dataloader))\n",
    "model_input, ground_truth = model_input.cuda(), ground_truth.cuda()\n",
    "\n",
    "for step in range(total_steps):\n",
    "    model_output, coords = img_siren(model_input)    \n",
    "    loss = ((model_output - ground_truth)**2).mean()\n",
    "    \n",
    "    if not step % steps_til_summary:\n",
    "        print(\"Step %d, Total loss %0.6f\" % (step, loss))\n",
    "        img_grad = gradient(model_output, coords)\n",
    "        img_laplacian = laplace(model_output, coords)\n",
    "\n",
    "        fig, axes = plt.subplots(1,3, figsize=(18,6))\n",
    "        axes[0].imshow(model_output.cpu().view(256,256).detach().numpy(), cmap='gray')\n",
    "        axes[1].imshow(img_grad.norm(dim=-1).cpu().view(256,256).detach().numpy())\n",
    "        axes[2].imshow(img_laplacian.cpu().view(256,256).detach().numpy())\n",
    "        plt.show()\n",
    "\n",
    "    optim.zero_grad()\n",
    "    loss.backward()\n",
    "    optim.step()"
   ],
   "id": "c78e230d2cc31809",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "with torch.no_grad():\n",
    "    coords = get_mgrid(2**10, 1) * 5 * np.pi\n",
    "    \n",
    "    sin_1 = torch.sin(coords)\n",
    "    sin_2 = torch.sin(coords * 2)\n",
    "    sum = sin_1 + sin_2\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(16,2))\n",
    "    ax.plot(coords, sum)\n",
    "    ax.plot(coords, sin_1)\n",
    "    ax.plot(coords, sin_2)\n",
    "    plt.title(\"Rational multiple\")\n",
    "    plt.show()\n",
    "    \n",
    "    sin_1 = torch.sin(coords)\n",
    "    sin_2 = torch.sin(coords * np.pi)\n",
    "    sum = sin_1 + sin_2\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(16,2))\n",
    "    ax.plot(coords, sum)\n",
    "    ax.plot(coords, sin_1)\n",
    "    ax.plot(coords, sin_2)\n",
    "    plt.title(\"Pseudo-irrational multiple\")\n",
    "    plt.show()"
   ],
   "id": "950cd432d4b124b3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "with torch.no_grad():\n",
    "    out_of_range_coords = get_mgrid(1024, 2) * 50\n",
    "    model_out, _ = img_siren(out_of_range_coords.cuda())\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(16,16))\n",
    "    ax.imshow(model_out.cpu().view(1024,1024).numpy())\n",
    "    plt.show()"
   ],
   "id": "24831fb01c753f61",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
